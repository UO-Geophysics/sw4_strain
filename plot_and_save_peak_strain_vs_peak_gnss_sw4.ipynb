{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b068a3-992e-48f0-aa29-677e77fd2195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy.core import read, Stream\n",
    "from obspy.taup import TauPyModel\n",
    "from obspy.geodetics import degrees2kilometers, kilometer2degrees, gps2dist_azimuth\n",
    "import pandas as pd\n",
    "from mudpy import fakequakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b91cb9db-9b3c-4336-9461-cb37d943d1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = '/Users/sydneydybing/SW4/'\n",
    "project_name = 'strain'\n",
    "path = home + project_name + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea332bd-0014-4731-a559-ed4daf44567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make or load our custom TauPyModel format velocity model\n",
    "\n",
    "custom_model = TauPyModel(model = path + 'structure/' + 'mojave_simpletop_forsw4.npz')\n",
    "\n",
    "# Only need to make the .npz one time, then we can just read it in. Uncomment below to remake\n",
    "\n",
    "# vel_mod_file = path + 'mojave_simpletop_forsw4.mod'\n",
    "# fakequakes.build_TauPyModel(home, project_name, vel_mod_file, background_model = 'PREM')\n",
    "# custom_model = TauPyModel(model = path + 'structure/' + 'mojave_simpletop_forsw4.npz')\n",
    "# default_model = TauPyModel(model = 'iasp91') # Non-custom one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "310bda80-950e-4fce-a73f-0828f699282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event info\n",
    "\n",
    "# Read in event location file \n",
    "event_file = 'M6_catalog_2004-2024.csv'\n",
    "eventLocs = pd.read_csv(path + event_file)\n",
    "\n",
    "# Pick your event\n",
    "event = eventLocs.iloc[11] # Ridgecrest mainshock\n",
    "\n",
    "hypo_lat = event.latitude\n",
    "hypo_lon = event.longitude\n",
    "hypo_depth = event.depth # km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24f1e936-ace7-441b-a786-9a57ffec2390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stations\n",
    "\n",
    "sta_file = 'bsm_metadata.csv'\n",
    "stas = pd.read_csv(path + sta_file)\n",
    "\n",
    "# Choose subset of stations\n",
    "rc_stas_sub = ['B072', 'B079', 'B082', 'B087', 'B916', 'B917', 'B918', 'B921'] # subset of stations close to Ridgecrest - 4 super close, 2 west, 2 south\n",
    "stas_sub = stas.query('BNUM in @rc_stas_sub').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d898024-f851-437c-a282-bef780317c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/s8qp7lfs59g_tbwsx_wxkdx80000gn/T/ipykernel_7500/2726806539.py:10: DeprecationWarning: `alltrue` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `all` instead.\n",
      "  dist_m, az, baz = gps2dist_azimuth(hypo_lat, hypo_lon, sta_lat, sta_lon) # dist in meters\n"
     ]
    }
   ],
   "source": [
    "# Add a column to the stations dataframe with the theoretical P-wave arrival times\n",
    "\n",
    "dists_km = []\n",
    "p_arr_times = []\n",
    "\n",
    "for idx in range(len(stas_sub)):\n",
    "    \n",
    "    sta_lat = stas_sub.LAT.values[idx]\n",
    "    sta_lon = stas_sub.LONG.values[idx]\n",
    "    dist_m, az, baz = gps2dist_azimuth(hypo_lat, hypo_lon, sta_lat, sta_lon) # dist in meters\n",
    "    \n",
    "    arrivals = custom_model.get_travel_times(source_depth_in_km = hypo_depth, \n",
    "                                  distance_in_degree = kilometer2degrees(dist_m/1000), phase_list=['p', 'P'])\n",
    "    p_arr_time = arrivals[0].time\n",
    "    \n",
    "    p_arr_times.append(p_arr_time)\n",
    "    dists_km.append(dist_m/1000)\n",
    "\n",
    "stas_sub['hypo_dist_km'] = dists_km\n",
    "stas_sub['p_arrival'] = p_arr_times\n",
    "\n",
    "stas_sub.to_csv(path + 'sw4_strain_stations_metadata.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6638cc3-6991-453f-8829-426951bbf419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving B072 figure\n",
      "Saving B079 figure\n",
      "Saving B082 figure\n",
      "Saving B087 figure\n",
      "Saving B916 figure\n",
      "Saving B917 figure\n",
      "Saving B918 figure\n",
      "Saving B921 figure\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(stas_sub)):\n",
    "    \n",
    "    sta = stas_sub.BNUM.values[idx]\n",
    "    theo_p_arr = stas_sub.p_arrival.values[idx]\n",
    "    hypo_dist = stas_sub.hypo_dist_km.values[idx]\n",
    "    \n",
    "    sw4_strain = pd.read_csv(path + 'multiseg_oneblock-results/' + sta + 's.txt', sep = '\\s+', skiprows = 16, names = ['time', 'xx', 'yy', 'zz', 'xy', 'xz', 'yz'])\n",
    "    sw4_gnss = pd.read_csv(path + 'multiseg_oneblock-results/' + sta + 'd.txt', sep = '\\s+', skiprows = 13, names = ['time', 'x', 'y', 'z'])\n",
    "    \n",
    "    ### Process strain data ###\n",
    "    \n",
    "    # Calculate horizontal RMS strain\n",
    "    time_strain = sw4_strain.time.values\n",
    "    xx_strain = sw4_strain.xx.values\n",
    "    xy_strain = sw4_strain.xy.values\n",
    "    yy_strain = sw4_strain.yy.values\n",
    "    rms_strain = np.sqrt((xx_strain**2 + xy_strain**2 + yy_strain**2)/3)\n",
    "    \n",
    "    # Calculate peak strain\n",
    "    strain_p_i = np.abs(time_strain - theo_p_arr).argmin() # Get the index where the P-wave arrives\n",
    "    mod_rms_strain = rms_strain.copy()\n",
    "    p_arr_strain = rms_strain[strain_p_i]\n",
    "    mod_rms_strain[:strain_p_i] = p_arr_strain # Strain before the P wave is set to be the same as the strain AT the P wave\n",
    "    peak_strain = mod_rms_strain.copy()\n",
    "    for k in range(0,len(mod_rms_strain)):\n",
    "        if k == 0:\n",
    "            strain = mod_rms_strain[0]\n",
    "            max_strain = strain\n",
    "        else:\n",
    "            # Grab progressively longer windows and save the biggest strain\n",
    "            strain = mod_rms_strain[:k+1] # Has to be k+1 because slicing doesn't include last one\n",
    "            max_strain = max(strain)\n",
    "        # Put peak strain back into the output stream\n",
    "        peak_strain[k] = max_strain \n",
    "    \n",
    "    ### Process GNSS data to match the strain processing ###\n",
    "    \n",
    "    # Calculate horizontal RMS GNSS  \n",
    "    time_gnss = sw4_gnss.time.values\n",
    "    x_gnss = sw4_gnss.x.values\n",
    "    y_gnss = sw4_gnss.y.values\n",
    "    rms_gnss = np.sqrt((x_gnss**2 + y_gnss**2)/2)\n",
    "    \n",
    "    # Calculate peak GNSS\n",
    "    gnss_p_i = np.abs(time_gnss - theo_p_arr).argmin() # Get the index where the P-wave arrives\n",
    "    mod_rms_gnss = rms_gnss.copy()\n",
    "    p_arr_gnss = rms_gnss[gnss_p_i]\n",
    "    mod_rms_gnss[:gnss_p_i] = p_arr_gnss # Strain before the P wave is set to be the same as the strain AT the P wave\n",
    "    peak_gnss = mod_rms_gnss.copy()\n",
    "    for k in range(0,len(mod_rms_gnss)):\n",
    "        if k == 0:\n",
    "            gnss = mod_rms_gnss[0]\n",
    "            max_gnss = gnss\n",
    "        else:\n",
    "            # Grab progressively longer windows and save the biggest strain\n",
    "            gnss = mod_rms_gnss[:k+1] # Has to be k+1 because slicing doesn't include last one\n",
    "            max_gnss = max(gnss)\n",
    "        # Put peak strain back into the output stream\n",
    "        peak_gnss[k] = max_gnss \n",
    "    \n",
    "    ### Make plots ###\n",
    "    \n",
    "    make_plots(sta, hypo_dist, theo_p_arr, time_strain, rms_strain, peak_strain, time_gnss, rms_gnss, peak_gnss, show_or_save = 'save')\n",
    "    \n",
    "    ### Save the new data ###\n",
    "    \n",
    "    both_rms_strain = np.column_stack((time_strain, rms_strain))\n",
    "    np.save(path + 'rms_and_peak_sw4_data/strain/rms/' + str(sta) + '.npy', both_rms_strain)\n",
    "    \n",
    "    both_rms_gnss = np.column_stack((time_gnss, rms_gnss))\n",
    "    np.save(path + 'rms_and_peak_sw4_data/gnss_at_strain_locs/rms/' + str(sta) + '.npy', both_rms_gnss)\n",
    "    \n",
    "    both_peak_strain = np.column_stack((time_strain, peak_strain))\n",
    "    np.save(path + 'rms_and_peak_sw4_data/strain/peak/' + str(sta) + '.npy', both_peak_strain)\n",
    "    \n",
    "    both_peak_gnss = np.column_stack((time_gnss, peak_gnss))\n",
    "    np.save(path + 'rms_and_peak_sw4_data/gnss_at_strain_locs/peak/' + str(sta) + '.npy', both_peak_gnss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae6c6336-e3e7-41a0-b1df-cd279ccf6aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting routine for the peak strain and peak GNSS calculated in one of the above cells\n",
    "\n",
    "def make_plots(sta, hypo_dist, theo_p_arr, time_strain, rms_strain, peak_strain, time_gnss, rms_gnss, peak_gnss, \n",
    "               show_or_save = 'show', plot_around_p = False, choose_your_own = False, xlim_low = None, xlim_high = None, plot_peak = True):\n",
    "  \n",
    "    # Set xlims\n",
    "    \n",
    "    if choose_your_own:\n",
    "        xlim_low = 0\n",
    "        xlim_high = 120\n",
    "    \n",
    "    if plot_around_p:\n",
    "        secs_around_p = 10\n",
    "        if theo_p_arr < secs_around_p: # If the theoretical P arrival is too close to the start of the waveform, start at the beginning\n",
    "            xlim_low = np.min(time_strain)\n",
    "        else:\n",
    "            xlim_low = theo_p_arr - around_p\n",
    "\n",
    "        if theo_p_arr > np.max(time_strain) - around_p: # If it's too close to the end of the waveform, end at the end\n",
    "            xlim_high = np.max(time_strain)\n",
    "        else:\n",
    "            xlim_high = theo_p_arr + around_p\n",
    "    \n",
    "    else: # Pick based on hypocentral distance groups for these specific stations      \n",
    "        if hypo_dist > 200:\n",
    "            xlim_low = 30\n",
    "            xlim_high = 90\n",
    "        else:\n",
    "            xlim_low = 0\n",
    "            xlim_high = 40\n",
    "    \n",
    "    if show_or_save == 'show':\n",
    "        dpi = 100\n",
    "    else:\n",
    "        dpi = 400\n",
    "        \n",
    "    fig = plt.figure(dpi = dpi)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title('Station ' + str(sta) + '\\nHypocentral distance ' + str(round(hypo_dist)) + ' km')\n",
    "    \n",
    "    if plot_peak:\n",
    "        ax.plot(time_strain, peak_strain, color = 'green', label = 'Peak strain')\n",
    "        ax.semilogy()\n",
    "        \n",
    "    else:\n",
    "        ax.plot(time_strain, rms_strain, color = 'red', label = 'RMS strain')\n",
    "        tol = 0.05\n",
    "        # Finds the index where the strain timeseries equals the low and high x limits you want\n",
    "        # Want the low y limit to be smaller than the minimum of the timeseries between the low and high xlims\n",
    "        # And the high y limit to be bigger than the maximum of the timeseries between the low and high xlims\n",
    "        ax_ylow_i = np.where(np.abs(time_strain - xlim_low) <= tol)[0][0]\n",
    "        ax_yhigh_i = np.where(np.abs(time_strain - xlim_high) <= tol)[0][0]\n",
    "        ax_ylim_low = np.min(rms_strain[ax_ylow_i:ax_yhigh_i]) * 0.9\n",
    "        ax_ylim_high = np.max(rms_strain[ax_ylow_i:ax_yhigh_i]) * 1.1\n",
    "        ax.set_ylim(ax_ylim_low, ax_ylim_high)\n",
    "    \n",
    "    ax2 = ax.twinx()\n",
    "    \n",
    "    if plot_peak:\n",
    "        ax2.plot(time_gnss, peak_gnss, color = 'orange', label = 'Peak GNSS')\n",
    "        ax2.semilogy()\n",
    "    else:\n",
    "        ax2.plot(time_gnss, rms_gnss, color = 'blue', label = 'RMS GNSS')\n",
    "        ax2_ylow_i = np.where(np.abs(time_gnss - xlim_low) <= tol)[0][0]\n",
    "        ax2_yhigh_i = np.where(np.abs(time_gnss - xlim_high) <= tol)[0][0]\n",
    "        ax2_ylim_low = np.min(rms_gnss[ax2_ylow_i:ax2_yhigh_i]) * 0.9\n",
    "        ax2_ylim_high = np.max(rms_gnss[ax2_ylow_i:ax2_yhigh_i]) * 1.1\n",
    "        ax2.set_ylim(ax2_ylim_low, ax2_ylim_high)\n",
    "    \n",
    "    ax.axvline(theo_p_arr, color = 'gray', linestyle = '--')\n",
    "    ax.set_xlim(xlim_low, xlim_high)\n",
    "    ax.legend(loc = 'lower right')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Strain')\n",
    "    \n",
    "    ax2.legend(loc = 'center right')\n",
    "    ax2.set_xlabel('Time (s)')\n",
    "    ax2.set_ylabel('Displacement (m)')\n",
    "    \n",
    "    if show_or_save == 'show':\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('Saving ' + str(sta) + ' figure')\n",
    "        plt.savefig(path + 'rms_and_peak_sw4_figs/' + str(sta) + '.png', format = 'PNG')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1602c6d0-90da-445a-a147-3cca9e8bd2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mudpy",
   "language": "python",
   "name": "mudpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

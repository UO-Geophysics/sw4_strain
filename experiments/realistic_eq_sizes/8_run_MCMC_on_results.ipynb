{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de86954a-4373-4d49-80a2-bd5be7548861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.core import Stream, read\n",
    "import numpy as np\n",
    "from pytensor.compile.ops import as_op\n",
    "import pytensor\n",
    "import pytensor.tensor as pt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os \n",
    "import os.path\n",
    "import pymc as pm\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c32a6d4-169e-495d-8642-e2202beaf968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What exactly are the colunns here? Amplitude of waves at a specific time?\n",
    "# My equivalent = peak strain at a specific time\n",
    "\n",
    "# Build the target function, misfit to this is what is being minimized\n",
    "@as_op(itypes=[pt.dvector,pt.dscalar,pt.dscalar,pt.dscalar,pt.dscalar,pt.dscalar], otypes=[pt.dvector]) # input variable types and output variable type(s)\n",
    "def two_straight_lines(x,m1,m2,xinter,x0,y0):\n",
    "    '''\n",
    "    input x coordiantes are in x\n",
    "    slopes are m1 and m2\n",
    "    intercept of left hand line is b1 \n",
    "    intersection of two lines is at xinter\n",
    "    \n",
    "    Note that y intercept of second straight line is dependent on b1 and xinter\n",
    "      and defined entirely by them (so that the lines touch).\n",
    "    '''\n",
    "    \n",
    "    # Output vector\n",
    "    y_out = np.ones(len(x))\n",
    "    \n",
    "    # Before building the first straight line, calculate the intercept\n",
    "    b1 = y0 - m1*x0\n",
    "    \n",
    "    # Build first straight line segment\n",
    "    y_out = m1*x + b1\n",
    "    \n",
    "    # Find points that are after the intersection and make the second segment\n",
    "    i = np.where(x>xinter)[0]\n",
    "    \n",
    "    # Define second y intercept\n",
    "    b2 = m1*xinter + b1 - m2*xinter\n",
    "    # print(b2)\n",
    "    \n",
    "    # Make second straight line\n",
    "    y_out[i] = m2*x[i] + b2\n",
    "\n",
    "    return y_out\n",
    "\n",
    "# Build the target function, misfit to this is what is being minimized\n",
    "def non_pytensor_two_straight_lines(x,m1,m2,xinter,x0,y0):\n",
    "    '''\n",
    "    input x coordiantes are in x\n",
    "    slopes are m1 and m2\n",
    "    intercept of left hand line is b1 \n",
    "    intersection of two lines is at xinter\n",
    "    \n",
    "    Note that y intercept of second straight line is dependent on b1 and xinter\n",
    "      and defined entirely by them (so that the lines touch).\n",
    "    '''\n",
    "    \n",
    "    # Output vector\n",
    "    yout = np.ones(len(x))\n",
    "    \n",
    "    # Before building the first straight line, calculate the intercept\n",
    "    b1 = y0 - m1*x0\n",
    "    \n",
    "    # Build first straight line segment\n",
    "    yout = m1*x + b1\n",
    "    \n",
    "    # Find points that are after the intersection and make the second segment\n",
    "    i = np.where(x>xinter)[0]\n",
    "    \n",
    "    # Define second y intercept\n",
    "    b2 = m1*xinter + b1 - m2*xinter\n",
    "    \n",
    "    # Make second straight line\n",
    "    yout[i] = m2*x[i] + b2\n",
    "\n",
    "    return yout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d16c76-6bbb-461b-b76c-9fe67d2147ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee9de8-98c4-4000-bcbf-6d0bde416626",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_list = []\n",
    "mags_list = []\n",
    "stas_list = []\n",
    "hypdist_list = []\n",
    "xhighs_list = []\n",
    "m1s_list = []\n",
    "m2s_list = []\n",
    "xinters_list = []\n",
    "sigmas_list = []\n",
    "trans_time_list = []\n",
    "\n",
    "for ii in range(len(events)):\n",
    "    \n",
    "    evt_id = events['evt_id'][ii]\n",
    "    print(evt_id)\n",
    "\n",
    "    for idx in range(len(snr_array)):\n",
    "\n",
    "        sta = snr_array['Sta'][idx]\n",
    "        \n",
    "        # Figure out the bounds for the MCMC based on the event and hypocentral distance (rainbow plots)\n",
    "        xlow = 10\n",
    "        \n",
    "        if evt_id == '2009-10-03_M6.1':\n",
    "            mag = '6.1'\n",
    "            hypdist = snr_array['2009_hyp_dist_km'][idx]\n",
    "            if sta == 'ZANB':\n",
    "                xhigh = 17\n",
    "            elif sta == 'NTTB' or sta == 'HGSB':\n",
    "                xhigh = 22\n",
    "            elif sta == 'FBRB':\n",
    "                xhigh = 29\n",
    "        elif evt_id == '2013-10-31_M6.3':\n",
    "            mag = '6.3'\n",
    "            hypdist = snr_array['2013_hyp_dist_km'][idx]\n",
    "            if sta == 'FBRB' or sta == 'SSTB' or sta == 'DONB':\n",
    "                xhigh = 30\n",
    "            elif sta == 'HGSB' or sta == 'CHMB' or sta == 'ZANB':\n",
    "                xhigh = 20\n",
    "            elif sta == 'TRKB' or sta == 'SJNB':\n",
    "                xhigh = 25\n",
    "            elif sta == 'SSNB':\n",
    "                xhigh = 15\n",
    "            else:\n",
    "                print('2013 sta typo ' + str(sta))\n",
    "        elif evt_id == '2018-02-04_M6.1':\n",
    "            mag = '6.1'\n",
    "            hypdist = snr_array['2018_hyp_dist_km'][idx]\n",
    "            if sta == 'TRKB' or sta == 'SJNB':\n",
    "                xhigh = 13\n",
    "            elif sta == 'HGSB' or sta == 'CHMB' or sta == 'SSNB' or sta == 'ZANB':\n",
    "                xhigh = 35\n",
    "            elif sta == 'FBRB' or sta == 'SSTB':\n",
    "                xhigh = 55\n",
    "            else:\n",
    "                print('2018 sta typo ' + str (sta))\n",
    "        \n",
    "        int_hypdist = int(hypdist)\n",
    "        \n",
    "        # if evt_id == '2013-10-31_M6.3' and sta == 'SSNB' or sta == 'SSTB':\n",
    "        #     pass\n",
    "        # elif evt_id == '2018-02-04_M6.1' and sta == 'TRKB':\n",
    "        #     pass\n",
    "        # else:\n",
    "        #     continue\n",
    "        \n",
    "        try:\n",
    "            pst = read(path + 'filtered_abs_peak_post_p_uncal/' + evt_id + '/' + sta + '.mseed')\n",
    "        except:\n",
    "            print('Skipping ' + sta + ', no data')\n",
    "            continue\n",
    "\n",
    "        print('Processing ' + str(sta))\n",
    "        \n",
    "        times = pst[0].times()\n",
    "        data = pst[0].data\n",
    "        log10_data = np.log10(data)\n",
    "        samp_rate = pst[0].stats.sampling_rate\n",
    "        print(samp_rate)\n",
    "        \n",
    "        vec_start = int(xlow*samp_rate)\n",
    "        vec_end = int(xhigh*samp_rate)\n",
    "\n",
    "        # Split into x and y vectors\n",
    "        xobserved = times[vec_start:vec_end]\n",
    "        yobserved = log10_data[vec_start:vec_end]\n",
    "        x0 = xobserved[0]\n",
    "        y0 = yobserved[0]\n",
    "        \n",
    "        # in order to pass the x variable into the target function it needs to be \n",
    "        # converted to a Theano \"shared\" variable\n",
    "        pt_xobserved = pytensor.shared(xobserved)\n",
    "        pt_x0 = pytensor.shared(x0)\n",
    "        pt_y0 = pytensor.shared(y0)\n",
    "            \n",
    "        # MCMC run parameters, these are good numbers for a \"production\" run. If you are\n",
    "        # fooling arund these can be lower to iterate faster\n",
    "        Nburn = 5000 # burn in samples that get discarded\n",
    "        Nmcmc = 15000 # bump to at least 5-10k\n",
    "        Nchains = 4\n",
    "        Ncores = 1\n",
    "        \n",
    "        # Bounds for the prior distributions\n",
    "        m1_low = -1; m1_high = 20\n",
    "        m2_low = -1; m2_high = 3\n",
    "        xinter_low = 10 ; xinter_high = 25 # location of the line slope change\n",
    "        \n",
    "        # Define the Bayesian model\n",
    "        with pm.Model()as model:\n",
    "            \n",
    "            # Use normal distributions as priors\n",
    "            m1 = pm.Uniform('m1', lower = m1_low, upper = m1_high)\n",
    "            m2 = pm.Uniform('m2', lower = m2_low, upper = m2_high)\n",
    "            # m1 = pm.Normal('m1', mu = 0.5, sigma = 1)\n",
    "            # m2 = pm.Normal('m2', mu = -0.1, sigma = 5)\n",
    "            xinter = pm.Uniform('xinter', lower = xinter_low, upper = xinter_high)\n",
    "            sigma = pm.HalfCauchy('sigma', beta = 10, initval = 1)\n",
    "        \n",
    "            # This is the model\n",
    "            likelihood = pm.Normal('y', mu = two_straight_lines(pt_xobserved,m1,m2,xinter,pt_x0,pt_y0),\n",
    "                                    observed = yobserved, sigma = sigma)\n",
    "\n",
    "            # NUTS sampler (default) is gradient based and won't work, use metropolis\n",
    "            step = pm.Metropolis(scaling = 0.1)\n",
    "            \n",
    "            # This runs the mcmc sampler\n",
    "            mcmc = pm.sample(Nmcmc, tune = Nburn, chains = Nchains, cores = Ncores, step = step)\n",
    "        \n",
    "        # Done, now is post-processing to get the data out of the sampler\n",
    "\n",
    "        posterior = az.extract(mcmc)\n",
    "        \n",
    "        # Unwrap coeficients - WRITE LINES TO SAVE THE ARRAYS!!!\n",
    "        m1_array = posterior.m1.values\n",
    "        m1 = np.mean(m1_array)\n",
    "        # print('m1 mean: ' + str(round(m1,2)))\n",
    "        \n",
    "        m2_array = posterior.m2.values\n",
    "        m2 = np.mean(m2_array)\n",
    "        # print('m2 mean: ' + str(round(m2,2)))\n",
    "        \n",
    "        xinter_array = posterior.xinter.values\n",
    "        xinter = np.mean(xinter_array)\n",
    "        # print('xinter Mean: ' + str(round(xinter,2)))\n",
    "        \n",
    "        sigma_array = posterior.sigma.values\n",
    "        sigma = np.mean(sigma_array)\n",
    "\n",
    "        # Lines!\n",
    "        b1 = y0 - m1*x0\n",
    "        b2 = m1*xinter + b1 - m2*xinter\n",
    "        \n",
    "        # Make plot to check stuff\n",
    "        xpredicted = np.arange(xobserved.min(), xobserved.max()+0.1, 0.1)\n",
    "        ypredicted = m1*xpredicted + b1\n",
    "        i = np.where(xpredicted > xinter)[0]\n",
    "        ypredicted[i] = m2*xpredicted[i] + b2\n",
    "        \n",
    "        # Get one-sigma region (need to obtain a ton of forward models and get stats)\n",
    "        N = len(posterior.m1.values)\n",
    "        \n",
    "        yfit = np.zeros((len(xpredicted), N))\n",
    "        for k in range(N):\n",
    "            yfit[:,k] = non_pytensor_two_straight_lines(xpredicted,m1_array[k],m2_array[k],xinter_array[k],x0,y0)\n",
    "        mu = yfit.mean(1)\n",
    "        sig = yfit.std(1) * 1.95 #for 95% confidence\n",
    "        mu_plus = mu + sig\n",
    "        mu_minus = mu - sig\n",
    "        \n",
    "        # Least squares\n",
    "        mls, bls = np.polyfit(xobserved, yobserved, 1)\n",
    "        \n",
    "        # Find the transition point in ypredicted\n",
    "        diff = np.round(np.diff(ypredicted), decimals = 5)\n",
    "        # print(diff)\n",
    "        first_slope = diff[0]\n",
    "        second_slope = diff[-1]\n",
    "        trans_idx = np.where((diff != first_slope) & (diff != second_slope))[0][0] + 1\n",
    "        \n",
    "        # Get the transition point\n",
    "        mcmc_trans_x = xpredicted[trans_idx] # Number\n",
    "        mcmc_trans_y = ypredicted[trans_idx]\n",
    "        \n",
    "        # Append things\n",
    "        events_list.append(evt_id)\n",
    "        mags_list.append(mag)\n",
    "        stas_list.append(sta)\n",
    "        hypdist_list.append(int_hypdist)\n",
    "        xhighs_list.append(xhigh)\n",
    "        m1s_list.append(m1)\n",
    "        m2s_list.append(m2)\n",
    "        xinters_list.append(xinter)\n",
    "        sigmas_list.append(sigma)\n",
    "        trans_time_list.append(mcmc_trans_x)\n",
    "        \n",
    "        # Create folder for the event\n",
    "        array_save_dir = path + 'mcmc_arrays_uncal/' + evt_id + '/' + sta + '/'\n",
    "        if os.path.isdir(array_save_dir):\n",
    "            pass\n",
    "        else:\n",
    "            os.makedirs(array_save_dir)\n",
    "\n",
    "        np.save(array_save_dir + 'xobserved.npy', xobserved)\n",
    "        np.save(array_save_dir + 'yobserved.npy', yobserved)\n",
    "        np.save(array_save_dir + 'xpredicted.npy', xpredicted)\n",
    "        np.save(array_save_dir + 'ypredicted.npy', ypredicted)\n",
    "        np.save(array_save_dir + 'forward_mus.npy', mu)\n",
    "        np.save(array_save_dir + 'foward_sigs.npy', sig)\n",
    "        \n",
    "        summary = az.summary(mcmc, fmt = 'wide')\n",
    "        print(summary)\n",
    "        summary.to_csv(array_save_dir + 'mcmc_summary.csv', index = False)\n",
    "        \n",
    "        # Folder for figures\n",
    "        fig_save_dir = path + 'mcmc_plots_uncal/' + evt_id + '/'\n",
    "        if os.path.isdir(fig_save_dir):\n",
    "            pass\n",
    "        else:\n",
    "            os.makedirs(fig_save_dir)\n",
    "        \n",
    "        az.plot_trace(mcmc)\n",
    "        # plt.show()\n",
    "        plt.savefig(fig_save_dir + sta + '_stats_plots.png', format = 'PNG')\n",
    "        plt.close()\n",
    "\n",
    "        # Plot all solutions\n",
    "        fig = plt.figure(dpi = 100)\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.set_title(str(sta))\n",
    "        \n",
    "        ax.plot(xobserved, yobserved, color = 'blue', label = 'Observed (log peak strain)')\n",
    "        ax.plot(xpredicted, ypredicted, color = 'red', label = 'Predicted (MCMC)')\n",
    "        # ax.plot(xpredicted, mu, color = 'green', linestyle = '--', label = 'yfit')\n",
    "        # ax.plot(xpredicted, xpredicted * mls + bls, color = 'orange', label = 'np.polyfit least squares')\n",
    "        ax.scatter(xpredicted[trans_idx], ypredicted[trans_idx], marker = 'o', color = 'black', label = 'Transition at ' + str(round(xpredicted[trans_idx],2)) + ' sec')\n",
    "        # ax.scatter(closest_trans_x, closest_trans_y, marker = 'o', color = 'green', label = 'Adjusted transition at ' + str(round(closest_trans_x,2)) + ' sec')\n",
    "        # ax2 = ax.twinx()\n",
    "        # ax2.plot(xobserved, pythags_arr, color = 'violet')\n",
    "        # ax2.axhline(closest_trans_x, color = 'violet', linestyle = '--')\n",
    "        ax.fill_between(xpredicted, mu_plus, mu_minus, color = 'gray', alpha = 0.2, label = '95% confidence') # 95% confidence interval\n",
    "        ax.set_xlabel('Time (s) - p-wave at 10s')\n",
    "        ax.set_ylabel('log10 of peak strain')\n",
    "        # ax.set_xlim(10,13)\n",
    "        ax.legend()\n",
    "        \n",
    "        # plt.show()\n",
    "            \n",
    "        plt.savefig(fig_save_dir + sta + '.png', format = 'PNG')\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "pymc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
